# üó∫Ô∏è Roadmap de Implementaci√≥n - M√≥dulo IA CloudDocs

**Rama:** `ia-infraestructura-first-version`  
**Fecha Inicio:** Febrero 20, 2026  
**Estado:** üöß En Progreso

---

## üìã √çndice de Fases

- [Fase 0: Setup de Entornos](#-fase-0-setup-de-entornos) (2-3h) **‚Üê EMPEZAMOS AQU√ç**
- [Fase 1: Cr√≠ticos - Seguridad y Abstracci√≥n](#-fase-1-cr√≠ticos---seguridad-y-abstracci√≥n) (8-10h)
- [Fase 2: Alta - Auto-procesamiento](#-fase-2-alta-prioridad---auto-procesamiento) (6-8h)
- [Fase 3: Media - Clasificaci√≥n e Indexaci√≥n](#-fase-3-media-prioridad---clasificaci√≥n-e-indexaci√≥n) (10-12h)
- [Fase 4: Baja - OCR y Summarization](#-fase-4-baja-prioridad---ocr-y-summarization) (8-10h)

**Tiempo Total Estimado:** 34-43 horas

---

## üéØ FASE 0: Setup de Entornos ‚úÖ COMPLETADA

**Objetivo:** Habilitar Ollama (local/gratis) y MockAI antes de implementar abstracci√≥n

**Estado:** ‚úÖ **COMPLETADA** (Febrero 20, 2026)

### Tareas Completadas

#### **‚úÖ TASK 0.1: Instalar y Configurar Ollama** (1h)

**Completado:**

- ‚úÖ Ollama 0.16.2 instalado correctamente
- ‚úÖ Modelos descargados:
  - `llama3.2:3b` (2.0 GB) - LLM para chat
  - `nomic-embed-text` (274 MB) - Embeddings (768 dims)
- ‚úÖ Servidor Ollama corriendo en `http://localhost:11434`
- ‚úÖ NPM package `ollama` instalado

**Configuraci√≥n en .env:**

```bash
AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3.2:3b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
```

---

#### **‚úÖ TASK 0.2: Crear Estructura de Proveedores** (1h)

**Archivos creados:**

```schema
src/services/ai/providers/
‚îú‚îÄ‚îÄ ai-provider.interface.ts       # Interface base ‚úÖ
‚îú‚îÄ‚îÄ openai.provider.ts             # Implementaci√≥n OpenAI ‚úÖ
‚îú‚îÄ‚îÄ ollama.provider.ts             # Implementaci√≥n Ollama ‚úÖ
‚îú‚îÄ‚îÄ mock.provider.ts               # Implementaci√≥n Mock ‚úÖ
‚îú‚îÄ‚îÄ provider.factory.ts            # Factory para seleccionar proveedor ‚úÖ
‚îî‚îÄ‚îÄ index.ts                       # Exports p√∫blicos ‚úÖ
```

**Caracter√≠sticas implementadas:**

- ‚úÖ Interface `AIProvider` con m√©todos: `generateEmbedding()`, `generateResponse()`, `classifyDocument()`, `summarizeDocument()`, `checkConnection()`
- ‚úÖ Tipos: `EmbeddingResult`, `ChatResult`, `GenerationOptions`, `ClassificationResult`, `SummarizationResult`
- ‚úÖ Factory pattern con variable `AI_PROVIDER` (openai | ollama | mock)
- ‚úÖ Taxonom√≠a `DOCUMENT_CATEGORIES` en `ai.types.ts`

**Validaci√≥n:**

```typescript
import { getAIProvider } from './providers';
const provider = getAIProvider();
console.log(provider.name); // 'ollama'
```

---

#### **‚úÖ TASK 0.3: Test de Integraci√≥n Ollama** (30min)

**Tests creados:**

- ‚úÖ `tests/integration/ai/ai-provider.test.ts` (13 tests)
- ‚úÖ `tests/integration/ai/ollama.provider.test.ts` (18 tests)

**Resultados:**

- ‚úÖ **31/31 tests pasando** (100% success rate)
- ‚úÖ Factory selecciona proveedor correcto
- ‚úÖ MockProvider genera embeddings (1536 dims)
- ‚úÖ OllamaProvider genera embeddings (768 dims)
- ‚úÖ Generaci√≥n de respuestas con llama3.2:3b
- ‚úÖ Clasificaci√≥n de documentos funcional
- ‚úÖ Summarization funcional
- ‚úÖ Manejo de errores robusto

**Tiempo de ejecuci√≥n:** ~58 segundos para suite completa de Ollama

---

### ‚úÖ Checklist Fase 0 - COMPLETADA

- [x] Ollama instalado y corriendo en `localhost:11434`
- [x] Modelos descargados: `llama3.2:3b` y `nomic-embed-text`
- [x] NPM package `ollama` instalado
- [x] Estructura de carpeta `providers/` creada
- [x] Interface `AIProvider` definida
- [x] `OllamaProvider` implementado y funcionando
- [x] `MockAIProvider` implementado
- [x] `OpenAIProvider` migrado (sin cambiar comportamiento)
- [x] `ProviderFactory` funcionando con `AI_PROVIDER` env var
- [x] Tests de integraci√≥n pasando para Ollama
- [x] **.env unificado** con toda la configuraci√≥n
- [x] **.env.example actualizado** con AI Provider config

---

### üìù Configuraci√≥n Unificada

**Archivo √∫nico:** Todo est√° en `.env` (y `.env.example` para referencia)

**Cambiar de proveedor:**

```bash
# Desarrollo local gratis con Ollama
AI_PROVIDER=ollama

# Producci√≥n con OpenAI (requiere API key)
AI_PROVIDER=openai

# Tests r√°pidos sin LLM real
AI_PROVIDER=mock
```

**No se requieren archivos adicionales** - `.env.local` fue eliminado.

---

## üî¥ FASE 1: Cr√≠ticos - Seguridad y Abstracci√≥n

**Duraci√≥n Estimada:** 8-10h  
**Issues:** RFE-AI-005 (cross-org leak) + RFE-AI-001 (abstracci√≥n)

---

### **RFE-AI-005: Arreglar Cross-Org Leak en RAG** (3-4h)

**Problema Actual:**  
La b√∫squeda vectorial en MongoDB Atlas (`rag.service.ts`) **NO filtra por `organizationId`**, permitiendo que usuarios de la Org A puedan obtener respuestas basadas en documentos de la Org B.

#### **TASK 1.1: Agregar `organizationId` a Chunks** (1h)

**Archivo:** `src/models/types/ai.types.ts`

```typescript
export interface IDocumentChunk {
  _id?: ObjectId;
  documentId: string;
  organizationId: string;  // üÜï NUEVO CAMPO
  content: string;
  embedding: number[];
  createdAt: Date;
  chunkIndex: number;
  wordCount: number;
}
```

**Migraci√≥n de Datos Existentes:**

Crear script: `scripts/migrate-add-org-to-chunks.ts`

```typescript
// Consultar todos los chunks
// Para cada chunk:
//   - Buscar documento en MongoDB local por documentId
//   - Actualizar chunk con organizationId del documento
```

**Ejecutar:**

```bash
npx ts-node scripts/migrate-add-org-to-chunks.ts
```

---

#### **TASK 1.2: Modificar `document-processor.service.ts`** (30min)

**Cambio:** Incluir `organizationId` al crear chunks

```typescript
async processDocument(
  documentId: string,
  organizationId: string,  // üÜï NUEVO PAR√ÅMETRO
  text: string
): Promise<IProcessingResult> {
  // ...
  const chunkDocuments: IDocumentChunk[] = chunks.map((content, index) => ({
    documentId,
    organizationId,  // üÜï AGREGAR
    content,
    embedding: embeddings[index],
    // ...
  }));
}
```

---

#### **TASK 1.3: Modificar `rag.service.ts` - Filtro Obligatorio** (1h)

**Cambios en b√∫squeda vectorial:**

```typescript
async search(
  query: string,
  organizationId: string,  // üÜï PAR√ÅMETRO OBLIGATORIO
  topK: number = TOP_K_RESULTS
): Promise<ISearchResult[]> {
  const queryEmbedding = await embeddingService.generateEmbedding(query);

  const results = await collection.aggregate([
    {
      $vectorSearch: {
        index: VECTOR_SEARCH_INDEX,
        path: 'embedding',
        queryVector: queryEmbedding,
        numCandidates: topK * 10,
        limit: topK,
        filter: {  // üÜï FILTRO POR ORGANIZACI√ìN
          organizationId: { $eq: organizationId }
        }
      }
    },
    // ...
  ]).toArray();
}
```

**Aplicar a:**

- `search()`
- `searchInDocument()`
- `answerQuestion()`
- `answerQuestionInDocument()`

---

#### **TASK 1.4: Actualizar Controlador** (30min)

**Archivo:** `src/controllers/ai.controller.ts`

```typescript
export async function askQuestion(req, res, next) {
  const { question, organizationId } = req.body;
  
  // Validar membership (ya existe)
  const isActiveMember = await hasActiveMembership(req.user!.id, organizationId);
  
  // Pasar organizationId a RAG
  const response = await ragService.answerQuestion(
    question,
    organizationId  // üÜï PASAR ORG ID
  );
}
```

---

#### **TASK 1.5: Tests de Seguridad Multitenancy** (1h)

**Crear:** `tests/integration/ai/multitenancy-rag.test.ts`

```typescript
describe('RAG Multitenancy Security', () => {
  it('should NOT return chunks from other organizations', async () => {
    // Crear 2 orgs
    const org1 = await OrganizationBuilder.create();
    const org2 = await OrganizationBuilder.create();
    
    // Documento en org1
    const doc1 = await DocumentBuilder.create({ organization: org1._id });
    await documentProcessor.processDocument(doc1._id, org1._id, 'Secret data org1');
    
    // Documento en org2
    const doc2 = await DocumentBuilder.create({ organization: org2._id });
    await documentProcessor.processDocument(doc2._id, org2._id, 'Secret data org2');
    
    // Buscar desde org1
    const results = await ragService.search('secret', org1._id.toString());
    
    // Verificar que SOLO retorna chunks de org1
    expect(results.every(r => r.chunk.organizationId === org1._id.toString())).toBe(true);
  });
});
```

---

### ‚úÖ Checklist RFE-AI-005

- [ ] Campo `organizationId` agregado a `IDocumentChunk`
- [ ] Script de migraci√≥n ejecutado
- [ ] `document-processor.service.ts` actualizado
- [ ] `rag.service.ts` con filtro `$eq organizationId`
- [ ] Todos los tests de seguridad pasando
- [ ] Verificado manualmente con 2 orgs diferentes

---

### **RFE-AI-001: Abstracci√≥n de AI Provider** (5-6h)

**Objetivo:** Refactorizar servicios para usar abstracci√≥n (ya creada en Fase 0)

#### **TASK 1.6: Migrar `embedding.service.ts` a usar Provider** (1.5h)

**Antes (actual):**

```typescript
class EmbeddingService {
  async generateEmbedding(text: string): Promise<number[]> {
    const openai = OpenAIClient.getInstance();
    const response = await openai.embeddings.create({ ... });
    return response.data[0].embedding;
  }
}
```

**Despu√©s:**

```typescript
class EmbeddingService {
  async generateEmbedding(text: string): Promise<number[]> {
    const provider = getAIProvider();  // üÜï Usa factory
    const result = await provider.generateEmbedding(text);
    return result.embedding;
  }
}
```

**Testing:**

```bash
# Test con OpenAI
AI_PROVIDER=openai npm test -- embedding.service.test.ts

# Test con Ollama
AI_PROVIDER=ollama npm test -- embedding.service.test.ts

# Test con Mock (r√°pido)
AI_PROVIDER=mock npm test -- embedding.service.test.ts
```

---

#### **TASK 1.7: Migrar `llm.service.ts` a usar Provider** (1.5h)

**Cambios similares:**

- Eliminar `require('../../configurations/openai-config')`
- Usar `getAIProvider().generateResponse()`
- Eliminar hack de `(global as any).__OPENAI_CREATE__`

---

#### **TASK 1.8: Manejo de Dimensiones Din√°micas** (2h)

**Problema:** OpenAI usa 1536 dims, Ollama usa 768 dims

**Soluci√≥n:**

1. **Agregar m√©todo a provider:**

```typescript
interface AIProvider {
  getEmbeddingDimensions(): number;
}
```

1. **Actualizar validaciones en `rag.service.ts`:**

```typescript
const provider = getAIProvider();
const expectedDims = provider.getEmbeddingDimensions();

if (embedding.length !== expectedDims) {
  throw new HttpError(400, `Expected ${expectedDims} dims, got ${embedding.length}`);
}
```

1. **√çndices vectoriales separados en Atlas:**
   - `vector_index_openai_1536` (para OpenAI)
   - `vector_index_ollama_768` (para Ollama)
   - Seleccionar √≠ndice seg√∫n provider activo

---

#### **TASK 1.9: Actualizar Tests Existentes** (1h)

**Modificar todos los tests que usan OpenAI directamente:**

```typescript
// Antes
import OpenAIClient from '...';

// Despu√©s
import { getAIProvider } from '...';
process.env.AI_PROVIDER = 'mock';  // Para tests r√°pidos
```

**Archivos a modificar:**

- `tests/unit/services/ai/*.test.ts`
- `tests/integration/ai/*.test.ts`

---

### ‚úÖ Checklist RFE-AI-001

- [ ] `embedding.service.ts` usa `getAIProvider()`
- [ ] `llm.service.ts` usa `getAIProvider()`
- [ ] Hack de `global.__OPENAI_CREATE__` eliminado
- [ ] M√©todo `getEmbeddingDimensions()` implementado
- [ ] Manejo de √≠ndices vectoriales din√°micos
- [ ] Todos los tests pasando con `AI_PROVIDER=mock`
- [ ] Tests de integraci√≥n pasando con `AI_PROVIDER=openai`
- [ ] Tests de integraci√≥n pasando con `AI_PROVIDER=ollama`
- [ ] README actualizado con configuraci√≥n de proveedores

---

## üü† FASE 2: Alta Prioridad - Auto-procesamiento

**Duraci√≥n Estimada:** 6-8h  
**Issue:** RFE-AI-002

---

### **RFE-AI-002: Campos AI en Document Model + Auto-Procesamiento** (6-8h)

#### **TASK 2.1: Extender Document Schema** (1h)

**Archivo:** `src/models/document.model.ts`

```typescript
const documentSchema = new Schema({
  // ... campos existentes ...

  // üÜï AI Metadata
  aiProcessingStatus: {
    type: String,
    enum: ['none', 'pending', 'processing', 'completed', 'failed'],
    default: 'none',
    index: true
  },
  aiCategory: {
    type: String,
    default: null,
    index: true
  },
  aiConfidence: {
    type: Number,
    min: 0,
    max: 1,
    default: null
  },
  aiTags: {
    type: [String],
    default: []
  },
  aiSummary: {
    type: String,
    default: null
  },
  aiKeyPoints: {
    type: [String],
    default: []
  },
  extractedText: {
    type: String,
    default: null,
    select: false  // No incluir por defecto (puede ser grande)
  },
  aiProcessedAt: {
    type: Date,
    default: null
  },
  aiError: {
    type: String,
    default: null
  }
});
```

**Migraci√≥n:**

```bash
# No requiere script - campos opcionales con defaults
```

---

#### **TASK 2.2: Crear Job de Procesamiento As√≠ncrono** (2h)

**Archivo:** `src/jobs/process-document-ai.job.ts`

```typescript
export async function processDocumentAI(documentId: string): Promise<void> {
  const doc = await DocumentModel.findById(documentId);
  
  try {
    // 1. Actualizar estado a 'processing'
    doc.aiProcessingStatus = 'processing';
    await doc.save();

    // 2. Extraer texto
    const extracted = await textExtractionService.extractText(doc.path, doc.mimeType);
    
    // 3. Guardar texto extra√≠do
    doc.extractedText = extracted.text;
    await doc.save();

    // 4. Procesar chunks + embeddings
    await documentProcessor.processDocument(
      doc._id.toString(),
      doc.organization.toString(),
      extracted.text
    );

    // 5. Clasificar (requiere RFE-AI-003)
    // const classification = await aiService.classifyDocument(extracted.text);
    // doc.aiCategory = classification.category;
    // doc.aiTags = classification.tags;

    // 6. Resumir (requiere RFE-AI-007)
    // const summary = await aiService.summarizeDocument(extracted.text);
    // doc.aiSummary = summary.summary;

    // 7. Marcar como completado
    doc.aiProcessingStatus = 'completed';
    doc.aiProcessedAt = new Date();
    await doc.save();

    console.log(`[ai-job] Document ${documentId} processed successfully`);
  } catch (error) {
    doc.aiProcessingStatus = 'failed';
    doc.aiError = error.message;
    await doc.save();
    console.error(`[ai-job] Failed to process document ${documentId}:`, error);
  }
}
```

---

#### **TASK 2.3: Integrar en Upload Controller** (1h)

**Archivo:** `src/controllers/document.controller.ts`

```typescript
export async function upload(req, res, next) {
  try {
    // ... l√≥gica actual de upload ...
    
    const document = await DocumentModel.create({
      filename,
      mimeType,
      // ...
      aiProcessingStatus: 'pending'  // üÜï Inicializar en pending
    });

    // üÜï Disparar procesamiento as√≠ncrono
    if (textExtractionService.isSupportedMimeType(document.mimeType)) {
      // No await - dispara y olvida
      processDocumentAI(document._id.toString())
        .catch(err => console.error('[upload] AI processing error:', err));
    }

    res.status(201).json({
      success: true,
      data: document
    });
  } catch (error) {
    next(error);
  }
}
```

---

#### **TASK 2.4: Endpoint de Estado de Procesamiento** (1h)

**Archivo:** `src/routes/document.routes.ts`

```typescript
/**
 * @route   GET /api/documents/:id/ai-status
 * @desc    Obtiene el estado de procesamiento AI de un documento
 */
router.get('/:id/ai-status', authMiddleware, documentController.getAIStatus);
```

**Controller:**

```typescript
export async function getAIStatus(req, res, next) {
  const document = await DocumentModel.findById(req.params.id)
    .select('aiProcessingStatus aiCategory aiTags aiSummary aiProcessedAt aiError');

  if (!document) {
    return next(new HttpError(404, 'Document not found'));
  }

  res.json({
    success: true,
    data: {
      status: document.aiProcessingStatus,
      category: document.aiCategory,
      tags: document.aiTags,
      summary: document.aiSummary,
      processedAt: document.aiProcessedAt,
      error: document.aiError
    }
  });
}
```

---

#### **TASK 2.5: Indexar metadata AI en Elasticsearch** (1h)

**Archivo:** `src/services/search.service.ts`

```typescript
async indexDocument(document: IDocument) {
  await esClient.index({
    index: 'documents',
    id: document._id.toString(),
    body: {
      // ... campos existentes ...
      
      // üÜï Campos AI
      aiCategory: document.aiCategory,
      aiTags: document.aiTags,
      aiSummary: document.aiSummary,
      extractedText: document.extractedText  // üÜï Ahora s√≠ tiene contenido
    }
  });
}
```

---

#### **TASK 2.6: Tests de Auto-procesamiento** (1h)

**Crear:** `tests/integration/ai/auto-processing.test.ts`

```typescript
describe('Auto-processing on Upload', () => {
  it('should auto-process document after upload', async () => {
    const file = createTestPDF('Test content');
    
    const response = await request(app)
      .post('/api/documents/upload')
      .attach('file', file)
      .set('Cookie', userToken);

    expect(response.body.data.aiProcessingStatus).toBe('pending');

    // Esperar procesamiento (usar polling o mock)
    await waitForProcessing(response.body.data._id);

    const doc = await DocumentModel.findById(response.body.data._id);
    expect(doc.aiProcessingStatus).toBe('completed');
    expect(doc.extractedText).toBeTruthy();
  });
});
```

---

### ‚úÖ Checklist RFE-AI-002

- [ ] Document schema extendido con campos AI
- [ ] Job `processDocumentAI` implementado
- [ ] Upload controller dispara procesamiento as√≠ncrono
- [ ] Endpoint `/ai-status` funcionando
- [ ] Elasticsearch indexa metadata AI
- [ ] Tests de auto-procesamiento pasando
- [ ] Documentaci√≥n actualizada

---

## üü° FASE 3: Media Prioridad - Clasificaci√≥n e Indexaci√≥n

**Duraci√≥n Estimada:** 10-12h

---

### **RFE-AI-003: Clasificaci√≥n Autom√°tica** (5-6h)

#### **TASK 3.1: Definir Taxonom√≠a de Categor√≠as** (30min)

**Archivo:** `src/models/types/ai.types.ts`

```typescript
export const DOCUMENT_CATEGORIES = [
  'Contrato',
  'Factura',
  'Informe',
  'Manual',
  'Pol√≠tica',
  'Presentaci√≥n',
  'Reporte Financiero',
  'Acta de Reuni√≥n',
  'Propuesta',
  'Otro'
] as const;

export type DocumentCategory = typeof DOCUMENT_CATEGORIES[number];
```

---

#### **TASK 3.2: Implementar `classifyDocument()` en Provider** (2h)

**Interface:**

```typescript
interface AIProvider {
  classifyDocument(text: string): Promise<ClassificationResult>;
}

interface ClassificationResult {
  category: DocumentCategory;
  confidence: number;
  tags: string[];
}
```

**Implementaci√≥n OpenAI:**

```typescript
async classifyDocument(text: string): Promise<ClassificationResult> {
  const prompt = `Analiza el siguiente documento y clasif√≠calo.

Categor√≠as posibles: ${DOCUMENT_CATEGORIES.join(', ')}

Texto:
${text.substring(0, 2000)}  // Primeros 2000 chars

Responde en JSON:
{
  "category": "...",
  "confidence": 0.95,
  "tags": ["tag1", "tag2", "tag3"]
}`;

  const response = await this.generateResponse(prompt);
  return JSON.parse(response);
}
```

---

#### **TASK 3.3: Integrar en Job de Procesamiento** (30min)

**Archivo:** `src/jobs/process-document-ai.job.ts`

```typescript
// Agregar despu√©s del paso 4
const provider = getAIProvider();
const classification = await provider.classifyDocument(extracted.text);

doc.aiCategory = classification.category;
doc.aiConfidence = classification.confidence;
doc.aiTags = classification.tags;
```

---

#### **TASK 3.4: Endpoint Manual de Clasificaci√≥n** (1h)

```typescript
/**
 * @route   POST /api/ai/documents/:id/classify
 * @desc    Clasifica manualmente un documento
 */
router.post('/documents/:id/classify', aiController.classifyDocument);
```

---

#### **TASK 3.5: Tests de Clasificaci√≥n** (1h)

```typescript
describe('Document Classification', () => {
  it('should classify invoice correctly', async () => {
    const invoiceText = 'FACTURA No. 12345\nFecha: 2026-02-20\nTotal: $1,000';
    const result = await provider.classifyDocument(invoiceText);
    expect(result.category).toBe('Factura');
    expect(result.confidence).toBeGreaterThan(0.8);
  });
});
```

---

### **RFE-AI-004: Indexar Contenido en Elasticsearch** (4-5h)

#### **TASK 3.6: Actualizar Mapping de Elasticsearch** (1h)

**Archivo:** `src/configurations/elasticsearch-config.ts`

```typescript
const documentMapping = {
  properties: {
    filename: { type: 'text' },
    mimeType: { type: 'keyword' },
    
    // üÜï Contenido completo
    extractedText: {
      type: 'text',
      analyzer: 'spanish',  // Analizar en espa√±ol
      fields: {
        keyword: { type: 'keyword' }
      }
    },
    
    // üÜï Metadata AI
    aiCategory: { type: 'keyword' },
    aiTags: { type: 'keyword' },
    aiSummary: { type: 'text', analyzer: 'spanish' }
  }
};
```

---

#### **TASK 3.7: Reindexar Documentos Existentes** (1h)

**Script:** `scripts/reindex-documents-es.ts`

```typescript
async function reindexAll() {
  const documents = await DocumentModel.find({ aiProcessingStatus: 'completed' });
  
  for (const doc of documents) {
    await searchService.indexDocument(doc);
  }
}
```

---

#### **TASK 3.8: B√∫squeda H√≠brida (ES + Vector)** (2h)

**Crear:** `src/services/hybrid-search.service.ts`

```typescript
export async function hybridSearch(
  query: string,
  organizationId: string
): Promise<SearchResult[]> {
  // 1. B√∫squeda tradicional en Elasticsearch (BM25)
  const esResults = await searchService.search(query, organizationId);
  
  // 2. B√∫squeda vectorial en MongoDB Atlas
  const vectorResults = await ragService.search(query, organizationId);
  
  // 3. Fusionar resultados (RRF - Reciprocal Rank Fusion)
  return mergeResults(esResults, vectorResults);
}
```

---

### ‚úÖ Checklist Fase 3

- [ ] Taxonom√≠a de categor√≠as definida
- [ ] `classifyDocument()` implementado en providers
- [ ] Clasificaci√≥n integrada en auto-procesamiento
- [ ] Endpoint manual de clasificaci√≥n
- [ ] Mapping de ES actualizado con `extractedText`
- [ ] Script de reindexaci√≥n ejecutado
- [ ] B√∫squeda h√≠brida implementada
- [ ] Tests de clasificaci√≥n pasando

---

## üü¢ FASE 4: Baja Prioridad - OCR y Summarization

**Duraci√≥n Estimada:** 8-10h

---

### **RFE-AI-006: OCR para PDFs Escaneados** (4-5h)

#### **TASK 4.1: Instalar Tesseract** (30min)

```bash
# Windows
winget install UB-Mannheim.TesseractOCR

# NPM
npm install tesseract.js pdf2pic --save
```

---

#### **TASK 4.2: Implementar OCR Service** (2h)

**Crear:** `src/services/ai/ocr.service.ts`

```typescript
export class OCRService {
  async extractTextFromScannedPDF(pdfPath: string): Promise<string> {
    // 1. Convertir PDF a im√°genes
    const images = await pdf2pic(pdfPath);
    
    // 2. OCR en cada imagen
    const texts = await Promise.all(
      images.map(img => tesseract.recognize(img))
    );
    
    // 3. Concatenar texto
    return texts.join('\n\n');
  }
}
```

---

#### **TASK 4.3: Integrar en Text Extraction** (1h)

**Archivo:** `src/services/ai/text-extraction.service.ts`

```typescript
async extractFromPdf(filePath: string): Promise<ITextExtractionResult> {
  const buffer = fs.readFileSync(filePath);
  const data = await pdfParse(buffer);
  
  // Si el texto est√° vac√≠o o muy corto, intentar OCR
  if (data.text.trim().length < 100) {
    console.log('[text-extraction] PDF appears scanned, using OCR...');
    const ocrText = await ocrService.extractTextFromScannedPDF(filePath);
    return { text: ocrText, /* ... */ };
  }
  
  return { text: data.text, /* ... */ };
}
```

---

### **RFE-AI-007: Endpoint de Summarization** (3-4h)

#### **TASK 4.4: Implementar `summarizeDocument()` en Provider** (1.5h)

```typescript
interface AIProvider {
  summarizeDocument(text: string): Promise<SummarizationResult>;
}

interface SummarizationResult {
  summary: string;      // 2-3 frases
  keyPoints: string[];  // 3-5 puntos clave
}
```

**Implementaci√≥n:**

```typescript
async summarizeDocument(text: string): Promise<SummarizationResult> {
  const prompt = `Resume el siguiente documento en 2-3 frases y extrae 3-5 puntos clave.

Texto:
${text.substring(0, 4000)}

Responde en JSON:
{
  "summary": "...",
  "keyPoints": ["...", "...", "..."]
}`;

  const response = await this.generateResponse(prompt);
  return JSON.parse(response);
}
```

---

#### **TASK 4.5: Endpoint de Summarization** (1h)

```typescript
/**
 * @route   POST /api/ai/documents/:id/summarize
 * @desc    Genera un resumen de un documento
 */
router.post('/documents/:id/summarize', aiController.summarizeDocument);
```

---

#### **TASK 4.6: Integrar en Auto-procesamiento** (30min)

```typescript
// En process-document-ai.job.ts
const summary = await provider.summarizeDocument(extracted.text);
doc.aiSummary = summary.summary;
doc.aiKeyPoints = summary.keyPoints;
```

---

### ‚úÖ Checklist Fase 4

- [ ] Tesseract instalado
- [ ] OCR service implementado
- [ ] Detecci√≥n autom√°tica de PDFs escaneados
- [ ] `summarizeDocument()` en providers
- [ ] Endpoint `/summarize` funcionando
- [ ] Summarization en auto-procesamiento
- [ ] Tests de OCR y summarization

---

## üìä Tracking de Progreso

### ‚úÖ Sprint 1: Setup (FASE 0) - COMPLETADO

- **Inicio:** Febrero 20, 2026
- **Fin:** Febrero 20, 2026
- **Duraci√≥n:** 2.5 horas (estimaci√≥n: 2.5h)
- **Entregable:** ‚úÖ Ollama funcionando + estructura de providers + 31 tests pasando
- **Estado:** **COMPLETADO AL 100%**

**Logros clave:**

- ‚úÖ Ollama 0.16.2 instalado con modelos llama3.2:3b (2GB) y nomic-embed-text (274MB)
- ‚úÖ Sistema de providers con Factory pattern implementado
- ‚úÖ OpenAIProvider, OllamaProvider, MockProvider funcionando
- ‚úÖ 31/31 tests de integraci√≥n pasando
- ‚úÖ Configuraci√≥n unificada en .env (eliminado .env.local)

---

### üü° Sprint 2: Cr√≠ticos (FASE 1) - PENDIENTE

- **Duraci√≥n:** 8-10 horas (2-3 d√≠as)
- **Entregable:** Cross-org leak arreglado + abstracci√≥n completa
- **Estado:** **PR√ìXIMO** üéØ

---

### ‚ö™ Sprint 3: Auto-procesamiento (FASE 2) - PENDIENTE

- **Duraci√≥n:** 2 d√≠as
- **Entregable:** Upload dispara procesamiento autom√°tico

---

### ‚ö™ Sprint 4: Clasificaci√≥n (FASE 3) - PENDIENTE

- **Duraci√≥n:** 3 d√≠as
- **Entregable:** Clasificaci√≥n autom√°tica + b√∫squeda de contenido

---

### ‚ö™ Sprint 5: Extras (FASE 4) - PENDIENTE

- **Duraci√≥n:** 2-3 d√≠as
- **Entregable:** OCR + Summarization

---

## üß™ Estrategia de Testing

### Tests por Fase

**‚úÖ Fase 0 (Completada):**

- ‚úÖ Integration tests con Ollama real (18 tests)
- ‚úÖ Unit tests con MockProvider (13 tests)
- ‚úÖ Factory pattern tests
- **Resultado:** 31/31 tests pasando

**Fase 0:**

- Integration tests con Ollama real
- Unit tests con MockProvider

**Fase 1:**

- Security tests para cross-org leak
- Tests con cada provider (openai, ollama, mock)

**Fase 2:**

- E2E test: upload ‚Üí auto-processing ‚Üí status endpoint
- Tests de jobs as√≠ncronos

**Fase 3:**

- Tests de clasificaci√≥n con diferentes tipos de documentos
- Tests de b√∫squeda h√≠brida

**Fase 4:**

- Tests con PDFs escaneados
- Tests de summarization

---

## üìù Notas de Implementaci√≥n

### Variables de Entorno Finales

```bash
# AI Provider Selection
AI_PROVIDER=openai  # openai | ollama | mock

# OpenAI (si AI_PROVIDER=openai)
OPENAI_API_KEY=sk-proj-...

# Ollama (si AI_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3.2:3b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# MongoDB Atlas
MONGO_ATLAS_URI=mongodb+srv://...

# Elasticsearch
ELASTICSEARCH_NODE=http://localhost:9200
```

---

## üéØ Criterios de √âxito

### ‚úÖ Fase 0 - COMPLETADA

‚úÖ Ollama genera embeddings y respuestas correctamente  
‚úÖ Se puede cambiar de provider con una variable de entorno  
‚úÖ Tests corren sin API keys con `AI_PROVIDER=mock`  
‚úÖ 31/31 tests de integraci√≥n pasando  
‚úÖ Configuraci√≥n unificada en .env

### Fase 1 - PR√ìXIMA üéØ

‚úÖ Usuario de Org A NO puede ver datos de Org B en RAG  
‚úÖ C√≥digo no depende directamente de OpenAI SDK  
‚úÖ Tests pasan con los 3 providers

### Fase 2

‚úÖ Subir documento dispara procesamiento autom√°tico  
‚úÖ Frontend puede consultar estado v√≠a `/ai-status`  
‚úÖ Metadata AI se guarda en Document model

### Fase 3

‚úÖ Documentos se clasifican autom√°ticamente  
‚úÖ B√∫squeda en Elasticsearch incluye contenido extra√≠do  
‚úÖ B√∫squeda h√≠brida mejora resultados de relevancia

### Fase 4

‚úÖ PDFs escaneados se procesan con OCR  
‚úÖ Endpoint de summarization genera res√∫menes coherentes

---

## üìå Estado Actual

**‚úÖ Fase 0 Completada** (Febrero 20, 2026)  
**üéØ Siguiente:** Fase 1 - Cr√≠ticos (Seguridad y Abstracci√≥n)

**Progreso Total:** 2.5h / 34-43h (6-7% completado)

**Para comenzar Fase 1:**

```bash
# Verificar que todo funcione
npm test

# Confirmar que AI_PROVIDER est√° configurado
grep AI_PROVIDER .env
```

---

_Este roadmap se actualizar√° conforme avancemos en la implementaci√≥n._
